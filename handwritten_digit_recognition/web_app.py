# ===============================================================
#  web_app.py ‚Äî Bloc 1 / 6
#  Imports, configuration, chargement des donn√©es, persistance
# ===============================================================

import os
import pickle
from datetime import datetime

import numpy as np
import streamlit as st
import cv2
from streamlit_drawable_canvas import st_canvas

# --- Modules internes ---
from persistence import (
    load_all_runs,
    load_runs_history,
    save_runs_history,
    save_full_run,
    get_hof_top3,
)
from training_lock import (
    try_acquire_lock,
    release_lock,
    is_training_in_progress,
)

import mnist_loader
from neural_network import Network


# ===============================================================
#    CSS ‚Äî Ajuste la hauteur du canvas
# ===============================================================

CANVAS_HEIGHT = 400

st.markdown(
    f"""
    <style>
    iframe[title="streamlit_drawable_canvas.st_canvas"] {{
        height: {CANVAS_HEIGHT}px !important;
    }}
    </style>
    """,
    unsafe_allow_html=True,
)


# ===============================================================
#    CONFIG STREAMLIT
# ===============================================================

st.set_page_config(
    page_title="MNIST Lab ‚Äì DL Playground",
    layout="wide"
)

st.title("üß† MNIST Deep Learning Lab")
st.caption("Petit labo interactif pour explorer ton r√©seau neuronal MNIST.")


# ===============================================================
#    CHARGEMENT DES DONN√âES MNIST
# ===============================================================

@st.cache_resource(show_spinner=True)
def load_data():
    train, val, test = mnist_loader.load_data_wrapper()
    return list(train), list(val), list(test)

training_data, validation_data, test_data = load_data()


# ===============================================================
#    CHARGEMENT DE TOUS LES RUNS (persistence)
# ===============================================================

if "all_runs" not in st.session_state:
    st.session_state.all_runs = load_all_runs()

if "runs_history" not in st.session_state:
    st.session_state.runs_history = load_runs_history()


# ===============================================================
#    √âTAT GLOBAL STREAMLIT
# ===============================================================

if "log_text" not in st.session_state:
    st.session_state.log_text = ""

if "current_run" not in st.session_state:
    st.session_state.current_run = None

if "metrics_history" not in st.session_state:
    st.session_state.metrics_history = []

if "weight_history" not in st.session_state:
    st.session_state.weight_history = {}

if "misclassified_cache" not in st.session_state:
    st.session_state.misclassified_cache = {}

if "log_placeholder" not in st.session_state:
    st.session_state.log_placeholder = None


# ===============================================================
#    UTILITAIRES
# ===============================================================

def append_log(msg: str):
    st.session_state.log_text += msg + "\n"

    placeholder = st.session_state.get("log_placeholder", None)
    if placeholder is not None:
        placeholder.text_area("Output", st.session_state.log_text, height=400)


def clear_log():
    st.session_state.log_text = ""


def softmax(a):
    a = a - np.max(a)
    exp = np.exp(a)
    return exp / np.sum(exp)


def forward_with_activations(net: Network, x):
    activations = [x]
    zs = []
    a = x
    for b, w in zip(net.biases, net.weights):
        z = np.dot(w, a) + b
        zs.append(z)
        a = net.sigmoid(z)
        activations.append(a)
    return zs, activations


def get_misclassified(net: Network, test_data, max_samples=32):
    samples = []
    for x, y in test_data:
        a = net.feedForward(x)
        y_pred = int(np.argmax(a))
        y_true = int(y)
        if y_pred != y_true:
            probs = softmax(a)
            samples.append((x, y_true, y_pred, probs))
            if len(samples) >= max_samples:
                break
    return samples


def compute_weight_stats(net: Network):
    weights = np.concatenate([w.ravel() for w in net.weights])
    return {
        "mean": float(np.mean(weights)),
        "std": float(np.std(weights)),
        "min": float(np.min(weights)),
        "max": float(np.max(weights)),
    }

# ===============================================================
#   web_app.py ‚Äî Bloc 2 / 6
#   Sidebar, onglets, Hall of Fame, chargement mod√®le actif
# ===============================================================


# ===============================================================
#   AFFICHAGE DU MOD√àLE ACTIF
# ===============================================================

if st.session_state.current_run is None:
    st.info("üéØ Aucun mod√®le actif. Entra√Æne un mod√®le ou s√©lectionne-en un dans le Hall of Fame.")
else:
    run = st.session_state.current_run
    st.success(
        f"**Mod√®le actif :** `{run['run_id']}` ‚Äî "
        f"({run.get('source', 'training')}) ‚Äî "
        f"Acc: {run.get('final_accuracy', 0)*100:.2f}%"
    )


# ===============================================================
#   SIDEBAR ‚Äì CONTR√îLES UTILISATEUR
# ===============================================================

st.sidebar.header("üéõÔ∏è Hyperparam√®tres")

epochs = st.sidebar.slider("Epochs", 1, 50, 10)
learning_rate = st.sidebar.slider("Learning rate (Œ∑)", 0.01, 5.0, 3.0, step=0.01)
mini_batch_size = st.sidebar.slider("Mini-batch size", 1, 100, 10)

st.sidebar.markdown("---")
st.sidebar.subheader("üß± Architecture")

hidden_size = st.sidebar.slider("Taille couche cach√©e", 10, 300, 100)

st.sidebar.markdown("---")
st.sidebar.subheader("‚öôÔ∏è Options d'entra√Ænement")

use_validation = st.sidebar.checkbox("Utiliser validation comme test", value=False)
limit_train = st.sidebar.number_input(
    "Limiter le nb d'exemples d'entra√Ænement (0 = tout)",
    min_value=0,
    max_value=len(training_data),
    value=0,
    step=1000,
)


# ===============================================================
#   STRUCTURE DES ONGLET
# ===============================================================

(
    tab_readme,
    tab_train,
    tab_draw,
    tab_activations,
    tab_weights,
    tab_metrics,
    tab_errors
) = st.tabs([
    "üìñ Readme",
    "üöÄ Entra√Ænement",
    "üñäÔ∏è Dessiner & Tester",
    "‚ú® Activations",
    "üßÆ Poids",
    "üìà M√©triques",
    "üïµÔ∏è Erreurs"
])


# ===============================================================
#   HALL OF FAME (TOP 3)
# ===============================================================

def draw_hall_of_fame():
    st.markdown("## üèÜ Hall of Fame (Top 3)")
    history = st.session_state.runs_history

    if not history:
        st.info("Aucun mod√®le enregistr√© pour l‚Äôinstant.")
        return

    top3 = get_hof_top3(history)

    cols = st.columns(len(top3))

    for i, entry in enumerate(top3):
        with cols[i]:
            st.markdown(
                f"""
                ### ü•á #{i+1}
                **Run ID :** `{entry['run_id']}`  
                **Accuracy :** `{entry['final_accuracy']*100:.2f}%`  
                **Hidden size :** `{entry['sizes'][1]}`  
                **Date :** `{entry['timestamp']}`
                """
            )

            if st.button(f"‚û°Ô∏è Utiliser {entry['run_id']}", key=f"hof_load_{i}"):
                # Charger un mod√®le depuis persistence
                full = st.session_state.all_runs.get(entry["run_id"])
                if full:
                    model_dict = full["model"]
                    net = Network(model_dict["sizes"])
                    net.weights = model_dict["weights"]
                    net.biases = model_dict["biases"]

                    # Mise √† jour du mod√®le actif
                    st.session_state.current_run = {
                        "run_id": entry["run_id"],
                        "sizes": entry["sizes"],
                        "timestamp": entry["timestamp"],
                        "final_accuracy": entry["final_accuracy"],
                        "model_path": entry["model_path"],
                        "source": "hall_of_fame",
                    }

                    # On recharge les caches associ√©es
                    st.session_state.metrics_history = full["metrics"]
                    st.session_state.weight_history = {
                        entry["run_id"]: full["weight_history"]
                    }
                    st.session_state.misclassified_cache = {
                        entry["run_id"]: full["misclassified"]
                    }

                    st.success(f"Mod√®le {entry['run_id']} charg√© depuis Hall of Fame !")
                    st.rerun()


# ===============================================================
#   web_app.py ‚Äî Bloc 3 / 6
#   Entra√Ænement, callbacks, verrou global, sauvegarde persistante
# ===============================================================


# ===============================================================
#   CALLBACK D‚ÄôENTRA√éNEMENT (Epoch ‚Üí Metrics + Weight History)
# ===============================================================

def make_epoch_callback(run_id):
    """
    Fonction appel√©e √† chaque epoch : enregistre les m√©triques et les poids.
    """
    def epoch_callback(epoch, metrics, network: Network):

        # --- Sauvegarde des m√©triques dans state ---
        entry = {"run_id": run_id, "epoch": epoch}
        entry.update(metrics)
        st.session_state.metrics_history.append(entry)

        # --- Sauvegarde des poids (premi√®re couche) ---
        if run_id not in st.session_state.weight_history:
            st.session_state.weight_history[run_id] = {
                "epochs": [],
                "w0_list": [],
            }

        hist = st.session_state.weight_history[run_id]
        hist["epochs"].append(epoch)

        # copie pour ne pas √™tre √©cras√©
        w0 = network.weights[0].copy()
        hist["w0_list"].append(w0)

    return epoch_callback


# ===============================================================
#   FONCTION PRINCIPALE DE TRAINING
# ===============================================================

def run_single_training(eta, batch, cfg_name="manual"):
    """
    D√©marre un entra√Ænement complet :
    - Acquisition du verrou global
    - Cr√©ation du run_id
    - Ex√©cute le SGD avec callbacks
    - Sauvegarde mod√®le + metrics + erreurs + poids
    - Lib√®re le verrou
    """

    # -----------------------------------------------------------
    # üîí VERROU GLOBAL : on v√©rifie que personne ne s‚Äôentra√Æne
    # -----------------------------------------------------------
    if not try_acquire_lock():
        st.error("üö´ Un entra√Ænement est d√©j√† en cours dans une autre session.")
        return None, None

    try:
        clear_log()

        # Choix du dataset d'entra√Ænement (limite optionnelle)
        if limit_train and limit_train > 0:
            train_sub = training_data[:limit_train]
        else:
            train_sub = training_data

        test_set = validation_data if use_validation else test_data

        # --- Cr√©er r√©seau ---
        sizes = [784, hidden_size, 10]
        net = Network(sizes)

        # Avant entra√Ænement on ne conna√Æt pas l‚Äôacc ‚Üí on met juste model number + date
        model_number = len(st.session_state.runs_history) + 1  # auto-incr√©ment
        run_id = f"M{model_number}_{datetime.now().strftime('%y%m%d')}"

        # --- Metadonn√©es en m√©moire ---
        st.session_state.current_run = {
            "run_id": run_id,
            "sizes": sizes,
            "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "config_name": cfg_name,
            "source": "training",
        }

        append_log(f"=== NEW RUN {run_id} ===")
        append_log(f"Architecture: {sizes}")
        append_log(f"Epochs={epochs}, eta={eta}, mini_batch={batch}")
        append_log(f"Train samples={len(train_sub)}, Test samples={len(test_set)}")

        # --- Entra√Ænement SGD ---
        net.SGD(
            training_data=train_sub,
            epochs=epochs,
            mini_batch_size=batch,
            eta=eta,
            test_data=test_set,
            log_fn=append_log,
            epoch_callback=make_epoch_callback(run_id),
        )

        # --- √âvaluer mod√®le final ---
        correct = net.evaluate(test_set)
        final_acc = correct / len(test_set)
        st.session_state.current_run["final_accuracy"] = final_acc

        append_log(f"Final accuracy: {final_acc:.4f}")

        # --- Erreurs (misclassified) ---
        miscls = get_misclassified(net, test_set)
        st.session_state.misclassified_cache[run_id] = miscls

        # --- Sauvegarde persistante compl√®te ---
        full_config = {
            "timestamp": st.session_state.current_run["timestamp"],
            "sizes": sizes,
            "config_name": cfg_name,
            "epochs": epochs,
            "learning_rate": eta,
            "mini_batch_size": batch,
            "use_validation": use_validation,
            "limit_train": limit_train,
        }

        save_full_run(
            run_id=run_id,
            net=net,
            final_accuracy=final_acc,
            metrics_history=[
                m for m in st.session_state.metrics_history if m["run_id"] == run_id
            ],
            weight_history=st.session_state.weight_history.get(run_id, {}),
            misclassified=miscls,
            config=full_config,
        )

        # Rajouter au cache global des runs
        st.session_state.all_runs[run_id] = {
            "model": {
                "sizes": sizes,
                "weights": net.weights,
                "biases": net.biases
            },
            "metrics": [
                m for m in st.session_state.metrics_history if m["run_id"] == run_id
            ],
            "weight_history": st.session_state.weight_history.get(run_id, {}),
            "misclassified": miscls,
            "config": full_config,
        }

        # Rajouter dans runs_history display
        st.session_state.runs_history = load_runs_history()

        append_log("‚úîÔ∏è Entra√Ænement termin√© et sauvegard√©.")

        return run_id, net

    finally:
        # üîì Lib√©ration du verrou global
        release_lock()
        append_log("Lock released.")

# ===============================================================
#   web_app.py ‚Äî Bloc 4 / 6
#   Interface de l‚Äôonglet Training : terminal, bouton start,
#   Hall of Fame, affichage du dernier run
# ===============================================================

# ==============================================================
#   ONGLET README
# ==============================================================

with tab_readme:
    st.subheader("Bienvenue dans le MNIST Deep Learning Lab üëã")

    st.markdown("""
## üìö Qu‚Äôest-ce que MNIST ?

MNIST, c‚Äôest un petit classique du machine learning.  
Il s‚Äôagit d‚Äôun jeu de donn√©es contenant **70 000 images de chiffres manuscrits** (de 0 √† 9), chacune en **28√ó28 pixels**.  
Les images proviennent de milliers de personnes diff√©rentes, ce qui en fait un terrain parfait pour apprendre comment un mod√®le reconna√Æt des motifs visuels.

En bref :  
> MNIST, c‚Äôest le *‚ÄúHello World‚Äù* du Deep Learning ‚Äî simple, propre, et id√©al pour comprendre les bases.

---

## üéØ 1. √Ä quoi sert cette application ?

Ce site te permet de **configurer**, **entra√Æner** et **tester** ton propre r√©seau de neurones, le tout sans √©crire une seule ligne de code.

Tu peux :

### üîß Configurer ton r√©seau
- Choisir la taille de la couche cach√©e  
- Ajuster les hyperparam√®tres (epochs, learning rate, mini-batch‚Ä¶)  
- Activer certaines options d‚Äôentra√Ænement  

### üöÄ Lancer l‚Äôentra√Ænement
- Suivre la progression dans un terminal en direct  
- Visualiser l‚Äô√©volution de l‚Äôaccuracy  
- Voir les erreurs, les activations internes et m√™me les poids appris par le mod√®le  

### ‚úèÔ∏è Tester le mod√®le
- Sur des images MNIST r√©elles  
- Ou en dessinant toi-m√™me un chiffre dans un canvas interactif

L‚Äôobjectif est p√©dagogique : comprendre *comment* un r√©seau apprend, et *pourquoi* il se trompe parfois.

---

## üß© 2. Comment fonctionne un r√©seau de neurones ? (Version simple)

Un r√©seau de neurones, c‚Äôest un ensemble de ‚Äúcouches‚Äù qui transforment progressivement une entr√©e (ici, une image 28√ó28) pour pr√©dire un chiffre.

### Structure typique :
- **Input** : 784 pixels (28√ó28)
- **Hidden layer** : une couche de neurones interm√©diaires
- **Output** : 10 neurones (un par chiffre 0‚Äì9)

√Ä chaque √©tape :

1. Les neurones re√ßoivent des nombres (les intensit√©s des pixels)
2. Ils les multiplient par des **poids**
3. Ils appliquent une fonction (sigmo√Øde)
4. Ils transmettent le r√©sultat √† la couche suivante

Pendant l‚Äôentra√Ænement, le mod√®le :

- fait une pr√©diction  
- mesure l‚Äôerreur  
- ajuste ses poids pour faire mieux au prochain passage  

En r√©p√©tant √ßa des milliers de fois ‚Üí il apprend.

---

## ‚öôÔ∏è 3. Les hyperparam√®tres : ce qu‚Äôils font, et comment les r√©gler

Les hyperparam√®tres sont les r√©glages qui influencent *comment* le mod√®le apprend.

### üî∏ **Epochs**
Le nombre de fois o√π le mod√®le passe sur **tout** le dataset.

- Peu : mod√®le pas assez entra√Æn√©  
- Trop : risque de m√©moriser inutilement  

üí° Pour MNIST : **10 √† 30 epochs suffisent largement**

---

### üî∏ **Learning rate (Œ∑)**
La ‚Äúvitesse d‚Äôapprentissage‚Äù.

- Trop faible ‚Üí apprentissage lent  
- Trop fort ‚Üí instable, le mod√®le oscille ou diverge  

üí° Pour ce r√©seau : **entre 0.5 et 3.0 fonctionne tr√®s bien**

---

### üî∏ **Mini-batch size**
Nombre d‚Äôexemples utilis√©s avant chaque mise √† jour des poids.

- Petit batch ‚Üí apprentissage plus ‚Äúvivant‚Äù, mais plus bruit√©  
- Gros batch ‚Üí plus stable, mais peut donner des r√©sultats moins bons  

üí° Valeurs conseill√©es : **10 √† 50**

---

## üß± 4. La couche cach√©e (Hidden Layer)

La couche cach√©e est le c≈ìur du mod√®le : c‚Äôest l√† qu‚Äôil apprend les **motifs** caract√©ristiques des chiffres :

- courbes  
- angles  
- tiges verticales  
- coins  
- boucles  
- etc.

Plus la hidden layer est grande :

- plus le mod√®le peut apprendre de choses  
- mais plus il devient lent, et plus il risque de surapprendre

üí° Pour MNIST : **entre 50 et 150 neurones**, c‚Äôest un bon compromis.

---

## üß™ 5. Les options d‚Äôentra√Ænement

### üî∏ Utiliser la validation comme test
Permet d‚Äô√©valuer le mod√®le *sans toucher au vrai jeu de test*.  
C‚Äôest pratique pour ajuster les hyperparam√®tres sans ‚Äútricher‚Äù sur les performances r√©elles.

### üî∏ Limiter le nombre d‚Äôexemples d‚Äôentra√Ænement
Tu peux choisir de n‚Äôentra√Æner le mod√®le que sur une partie du dataset.

Utile pour :
- des tests rapides  
- √©conomiser les ressources  
- observer comment la quantit√© de donn√©es influence l‚Äôapprentissage  

üí° 0 = utiliser tout MNIST (valeur normale)

---

## üöÄ 6. Lancer l‚Äôentra√Ænement

1. Choisis :
   - la taille de la hidden layer  
   - les hyperparam√®tres  
   - les options d‚Äôentra√Ænement  

2. Clique sur **Start training**

3. Observe :
   - le terminal qui se met √† jour  
   - les courbes d‚Äô√©volution  
   - les erreurs et activations internes  
   - les poids du r√©seau  

√Ä la fin, un mod√®le est automatiquement sauvegard√©.

---

## ‚úèÔ∏è 7. Tester ton mod√®le (canvas de dessin)

Dans l‚Äôonglet **üñäÔ∏è Dessiner & Tester** :

- s√©lectionne un mod√®le sauvegard√©  
- dessine un chiffre √† la souris  

Le dessin est automatiquement :

- converti en image 28√ó28  
- normalis√©  
- pass√© au mod√®le

Le r√©seau te renvoie :
- sa pr√©diction  
- les probabilit√©s associ√©es (softmax)

---

N‚Äôh√©site pas √† explorer, tester plusieurs hyperparam√®tres et comparer les r√©sultats.  
Amuse-toi bien avec le Deep Learning üôÇ
""")


# ===============================================================
#   ONGLET TRAINING
# ===============================================================

with tab_train:

    # -----------------------------------------------------------
    #   COLONNE GAUCHE : D√©marrer un entra√Ænement
    # -----------------------------------------------------------
    col_left, col_right = st.columns([2, 1])

    with col_left:

        st.subheader("üöÄ Lancer un nouvel entra√Ænement")

        # Bouton Start Training
        start_training = st.button("üî• Start Training", disabled=is_training_in_progress())

        if is_training_in_progress():
            st.warning("‚è≥ Un entra√Ænement est d√©j√† en cours. Veuillez patienter...")

        st.markdown("### üì° Terminal")

        # Cr√©ation du placeholder si inexistant
        if st.session_state.log_placeholder is None:
            st.session_state.log_placeholder = st.empty()

        # Affichage du terminal
        st.session_state.log_placeholder.text_area(
            "Output",
            value=st.session_state.log_text,
            height=400,
        )


    # -----------------------------------------------------------
    #   COLONNE DROITE : Dernier run
    # -----------------------------------------------------------
    with col_right:
        st.subheader("üìù Dernier run")

        run = st.session_state.current_run

        if run is None:
            st.info("Aucun run pour le moment.")
        else:
            st.write(f"**Run ID :** `{run['run_id']}`")
            st.write(f"**Date :** {run['timestamp']}`")
            st.write(f"**Architecture :** `{run['sizes']}`")

            if "final_accuracy" in run:
                st.metric("Accuracy test", f"{run['final_accuracy']*100:.2f} %")
            else:
                st.info("Aucune accuracy disponible (run en cours ?).")

        st.markdown("---")

        # Hall of Fame
        draw_hall_of_fame()


    # -----------------------------------------------------------
    #   LANCEMENT D‚ÄôUN RUN
    # -----------------------------------------------------------
    if start_training and not is_training_in_progress():
        # On r√©initialise les structures par run
        st.session_state.metrics_history = [
            m for m in st.session_state.metrics_history
            if m["run_id"].startswith("dummy_never")
        ]
        st.session_state.weight_history = {}
        st.session_state.misclassified_cache = {}

        # Lancer l'entra√Ænement
        run_single_training(
            eta=learning_rate,
            batch=mini_batch_size,
            cfg_name="manual"
        )

        # Forcer rafra√Æchissement Streamlit pour afficher les r√©sultats
        st.rerun()

# ===============================================================
#   web_app.py ‚Äî Bloc 5 / 6
#   M√©triques (graphs), Poids, Activations, Erreurs,
#   TSNE / PCA, Matrice de confusion
# ===============================================================


# ===============================================================
#     ONGLET M√âTRIQUES
# ===============================================================

with tab_metrics:
    st.subheader("üìà M√©triques d'entra√Ænement et performance")

    if not st.session_state.metrics_history:
        st.info("Aucune m√©trrique disponible. Entra√Æne un mod√®le.")
    else:
        import pandas as pd

        df = pd.DataFrame(st.session_state.metrics_history)
        run_ids = df["run_id"].unique().tolist()

        selected_run = st.selectbox("S√©lectionne un run", run_ids)
        df_run = df[df["run_id"] == selected_run].sort_values("epoch")

        # === LIGNE DE 2 COLONNES ===
        col1, col2 = st.columns(2)

        # === COURBE D'ACCURACY ===
        with col1:
            st.markdown("### Accuracy par epoch")
            if "test_accuracy" in df_run:
                st.line_chart(
                    df_run.set_index("epoch")["test_accuracy"],
                    height=300
                )

        # === COURBE DE NB DE PR√âDICTIONS CORRECTES ===
        with col2:
            st.markdown("### Pr√©dictions correctes par epoch")
            if "test_correct" in df_run:
                st.bar_chart(
                    df_run.set_index("epoch")["test_correct"],
                    height=300
                )


    st.markdown("---")

    with st.expander("üß† Loss par epoch"):

        st.markdown(
            """
        La **loss** mesure √† quel point le mod√®le se trompe en moyenne.

        - Apr√®s chaque epoch, on calcule une valeur de loss sur le jeu d'entra√Ænement.
        - Normalement, la loss doit **descendre** progressivement si le mod√®le apprend correctement.
        """
        )

        if not st.session_state.metrics_history:
            st.info("Aucune m√©trique disponible.")
        else:
            df = pd.DataFrame(st.session_state.metrics_history)
            run_ids = df["run_id"].unique().tolist()

            selected_run_loss = st.selectbox(
                "S√©lectionner un run",
                run_ids,
                key="loss_selector"
            )

            df_run_loss = df[df["run_id"] == selected_run_loss].sort_values("epoch")

            if "train_loss" in df_run_loss:
                st.line_chart(
                    df_run_loss.set_index("epoch")["train_loss"],
                    height=300
                )

                st.metric(
                    "Derni√®re loss enregistr√©e",
                    f"{df_run_loss['train_loss'].iloc[-1]:.4f}"
                )


    # ============================================================
    #   üß© TSNE / PCA des activations internes
    # ============================================================

    with st.expander("üß© Visualisation TSNE / PCA de la hidden layer"):
        st.markdown(
            """
            On projette ici les activations de la **couche cach√©e** dans un plan 2D
            pour voir comment le r√©seau s√©pare les chiffres dans son espace interne.

            Chaque point = une image MNIST, color√©e selon son vrai chiffre.
            """
        )

        if st.session_state.current_run is None:
            st.info("Aucun mod√®le actif.")
        else:
            run_id = st.session_state.current_run["run_id"]
            full = st.session_state.all_runs.get(run_id)

            if not full:
                st.error("Impossible de charger les donn√©es du mod√®le.")
            else:
                model_dict = full["model"]
                net = Network(model_dict["sizes"])
                net.weights = model_dict["weights"]
                net.biases = model_dict["biases"]

                import pandas as pd
                import altair as alt
                from sklearn.decomposition import PCA
                from sklearn.manifold import TSNE

                max_samples = len(test_data)

                n_samples = st.slider(
                    "Nombre d'images",
                    100, min(2000, max_samples),
                    500
                )
                method = st.radio(
                    "M√©thode",
                    ["PCA", "t-SNE"]
                )

                if st.button("Calculer projection 2D"):
                    X = []
                    y_labels = []

                    for i, (x, y_true) in enumerate(test_data[:n_samples]):
                        _, acts = forward_with_activations(net, x)
                        hidden = acts[1]
                        X.append(hidden.ravel())
                        y_labels.append(int(y_true))

                    X = np.array(X)

                    if method == "PCA":
                        reducer = PCA(n_components=2)
                    else:
                        reducer = TSNE(
                            n_components=2,
                            learning_rate="auto",
                            init="random",
                            perplexity=min(30, n_samples - 1),
                        )

                    with st.spinner("Calcul..."):
                        emb = reducer.fit_transform(X)

                    df_emb = pd.DataFrame({
                        "x": emb[:, 0],
                        "y": emb[:, 1],
                        "label": y_labels,
                    })

                    chart = alt.Chart(df_emb).mark_circle(size=50, opacity=0.8).encode(
                        x="x",
                        y="y",
                        color="label:N",
                        tooltip=["label"]
                    )

                    st.altair_chart(chart, use_container_width=True)

    # ============================================================
    #   üéûÔ∏è Animation de l'√©volution des poids d'un neurone
    # ============================================================

    with st.expander("üéûÔ∏è Animation des poids d'un neurone (hidden layer)"):

        st.markdown(
            """
            Chaque neurone de la couche cach√©e poss√®de **784 poids** (un par pixel).  
            Si on reshape ce vecteur en 28√ó28, on obtient une image qui repr√©sente **le motif auquel ce neurone est sensible**.

            Id√©e de visualisation :
            - pour un neurone donn√©,
            - on enregistre ses poids √† diff√©rents epochs,
            - puis on affiche une **s√©rie d‚Äôimages** (ou un slider temporel) qui montre comment ce motif √©volue.

            Ce que l‚Äôon voit :
            - au d√©but, les poids ressemblent √† du bruit ;
            - progressivement, des formes apparaissent (traits verticaux, courbes, zones sombres/claires) ;
            - le neurone se ‚Äúsp√©cialise‚Äù dans un type de motif.

            > C‚Äôest une excellente mani√®re d‚Äôillustrer qu‚Äôun r√©seau n‚Äôest pas une bo√Æte noire magique, mais qu‚Äôil apprend effectivement des patrons visuels.
            """
        )

        if not st.session_state.weight_history:
            st.info("Aucun historique de poids disponible.")
        else:
            run_ids_w = list(st.session_state.weight_history.keys())
            sel_run = st.selectbox("S√©lectionner un run", run_ids_w)

            hist = st.session_state.weight_history[sel_run]
            epochs_hist = hist["epochs"]
            w0_list = hist["w0_list"]

            hidden_size_hist = w0_list[0].shape[0]

            neuron_idx = st.slider(
                "Neurone",
                0, hidden_size_hist - 1,
                0
            )
            epoch_pos = st.slider(
                "Position epoch",
                0, len(epochs_hist) - 1,
                len(epochs_hist) - 1
            )

            w_vec = w0_list[epoch_pos][neuron_idx, :]
            img = w_vec.reshape(28, 28)

            mn, mx = img.min(), img.max()
            if mx > mn:
                img_norm = (img - mn) / (mx - mn)
            else:
                img_norm = np.zeros_like(img)

            st.image(
                img_norm,
                width=160,
                caption=f"Run {sel_run} ‚Äî neurone {neuron_idx}, epoch {epochs_hist[epoch_pos]}"
            )


    # ============================================================
    #   üßÆ Matrice de confusion
    # ============================================================

    with st.expander("üßÆ Matrice de confusion"):

        st.markdown(
            """
        La **matrice de confusion** r√©sume comment le mod√®le se trompe entre les classes.

        - en lignes : la *vraie* classe (0, 1, 2, ‚Ä¶, 9)
        - en colonnes : la classe *pr√©dite* par le mod√®le
        - chaque case contient le nombre d‚Äôexemples correspondant

        On s‚Äôattend √† ce que la **diagonale** soit dominante (bonnes pr√©dictions).
        """
        )

        if st.session_state.current_run is None:
            st.info("Aucun mod√®le actif.")
        else:
            run_id = st.session_state.current_run["run_id"]
            full = st.session_state.all_runs.get(run_id)

            if not full:
                st.warning("Impossible de charger le mod√®le.")
            else:
                model_dict = full["model"]
                net = Network(model_dict["sizes"])
                net.weights = model_dict["weights"]
                net.biases = model_dict["biases"]

                dataset_choice = st.radio(
                    "Dataset",
                    ["Test", "Validation"],
                    horizontal=True
                )
                data = test_data if dataset_choice == "Test" else validation_data

                n_samples = st.slider(
                    "Nombre d'images",
                    100,
                    len(data),
                    min(1000, len(data))
                )

                if st.button("Calculer matrice"):
                    with st.spinner("Calcul en cours..."):
                        cm = np.zeros((10, 10), dtype=int)
                        subset = data[:n_samples]

                        for x, y_true in subset:
                            a = net.feedForward(x)
                            y_pred = int(np.argmax(a))
                            y_true = int(y_true)
                            cm[y_true, y_pred] += 1

                    st.write("### Accuracy :")
                    acc = np.trace(cm) / cm.sum()
                    st.metric("Accuracy", f"{acc*100:.2f}%")

                    import pandas as pd
                    import seaborn as sns
                    import matplotlib.pyplot as plt

                    df_cm = pd.DataFrame(cm)
                    fig, ax = plt.subplots()
                    sns.heatmap(df_cm, annot=False, cmap="Blues", ax=ax)
                    st.pyplot(fig)


# ===============================================================
#     ONGLET ERREURS
# ===============================================================

with tab_errors:
    st.subheader("üïµÔ∏è Images mal class√©es")

    if st.session_state.current_run is None:
        st.info("Aucun mod√®le actif.")
    else:
        run_id = st.session_state.current_run["run_id"]
        errors = st.session_state.misclassified_cache.get(run_id)

        if not errors:
            st.info("Aucune erreur disponible.")
        else:
            cols = st.columns(8)
            for i, (x, y_true, y_pred, probs) in enumerate(errors):
                col = cols[i % len(cols)]
                img = np.reshape(x, (28, 28))
                col.image(img, width=60, caption=f"T:{y_true}/P:{y_pred}")


# ===============================================================
#     ONGLET ACTIVATIONS
# ===============================================================

with tab_activations:
    st.subheader("‚ú® Explorateur d'activations internes")

    st.markdown(
        """
        Cet onglet permet d‚Äôexplorer ce qui se passe *√† l‚Äôint√©rieur* du r√©seau de neurones
        lorsqu‚Äôil traite une image MNIST.

        √Ä partir d‚Äôune image du jeu de test :

        - tu vois sa **distribution de probabilit√©s** en sortie (softmax),
        - tu peux analyser les **activations de chaque couche**,
        - et visualiser la **norme des activations**, qui donne une id√©e de l‚Äôintensit√© de la r√©ponse du r√©seau.

        L‚Äôobjectif est de mieux comprendre comment chaque couche transforme l‚Äôinformation
        et comment le r√©seau ¬´ r√©agit ¬ª √† une image donn√©e.

        En changeant l'index de l‚Äôimage, tu peux comparer les activations pour diff√©rents chiffres.

        """
    )
    if st.session_state.current_run is None:
        st.info("Aucun mod√®le actif.")
    else:
        run_id = st.session_state.current_run["run_id"]
        full = st.session_state.all_runs.get(run_id)

        if not full:
            st.warning("Impossible de charger le mod√®le.")
        else:
            model_dict = full["model"]
            net = Network(model_dict["sizes"])
            net.weights = model_dict["weights"]
            net.biases = model_dict["biases"]

            idx = st.slider(
                "Index MNIST",
                0, len(test_data) - 1,
                0
            )

            x, y_true = test_data[idx]
            img = x.reshape(28, 28)

            colA, colB = st.columns([1, 2])

            with colA:
                st.image(img, width=140, caption=f"Label : {y_true}")

            with colB:
                zs, activations = forward_with_activations(net, x)
                output = activations[-1]
                probs = softmax(output)

                import pandas as pd

                df_probs = pd.DataFrame({
                    "digit": list(range(10)),
                    "proba": probs.ravel()
                })
                st.bar_chart(df_probs.set_index("digit"))

                norms = [float(np.linalg.norm(a)) for a in activations]
                df_norms = pd.DataFrame({
                    "layer": list(range(len(norms))),
                    "activation_norm": norms,
                })
                st.line_chart(df_norms.set_index("layer"))


# ===============================================================
#     ONGLET POIDS
# ===============================================================

with tab_weights:
    st.subheader("üßÆ Analyse des poids")

    st.markdown(
        """
        Ici, tu visualises ce que le r√©seau a appris :

        - Les **poids de la couche cach√©e** montrent les motifs auxquels chaque neurone est sensible.
        - Les **poids de sortie** montrent comment ces motifs sont combin√©s pour reconna√Ætre chaque chiffre.

        C‚Äôest une fa√ßon rapide de voir ce que le mod√®le ‚Äúregarde‚Äù dans les images.
        """
    )

    if st.session_state.current_run is None:
        st.info("Aucun mod√®le actif.")
    else:
        run_id = st.session_state.current_run["run_id"]
        full = st.session_state.all_runs.get(run_id)

        if not full:
            st.warning("Impossible de charger le mod√®le.")
        else:
            model_dict = full["model"]
            net = Network(model_dict["sizes"])
            net.weights = model_dict["weights"]
            net.biases = model_dict["biases"]

            stats = compute_weight_stats(net)
            c1, c2, c3, c4 = st.columns(4)

            c1.metric("Mean", f"{stats['mean']:.4e}")
            c2.metric("Std", f"{stats['std']:.4e}")
            c3.metric("Min", f"{stats['min']:.4e}")
            c4.metric("Max", f"{stats['max']:.4e}")

            st.markdown("---")
            st.markdown("### Poids input ‚Üí hidden")

            w0 = net.weights[0]
            cols = st.columns(10)
            for i in range(min(10, w0.shape[0])):
                col = cols[i % len(cols)]
                img = w0[i, :].reshape(28, 28)

                mn, mx = img.min(), img.max()
                if mx > mn:
                    img_norm = (img - mn) / (mx - mn)
                else:
                    img_norm = np.zeros_like(img)

                col.image(img_norm, width=60, caption=f"N {i}")

            st.markdown("---")
            st.markdown("### Poids hidden ‚Üí output")

            w_out = net.weights[-1]
            w_hidden = net.weights[0]

            cols = st.columns(10)
            for digit in range(10):
                col = cols[digit % len(cols)]

                combined = np.dot(w_out[digit], w_hidden)
                img = combined.reshape(28, 28)

                mn, mx = img.min(), img.max()
                if mx > mn:
                    img_norm = (img - mn) / (mx - mn)
                else:
                    img_norm = np.zeros_like(img)

                col.image(img_norm, width=60, caption=f"Classe {digit}")

# ===============================================================
#   web_app.py ‚Äî Bloc 6 / 6
#   Onglet : üñäÔ∏è Dessiner & Tester
# ===============================================================

with tab_draw:
    st.subheader("üñäÔ∏è Dessine un chiffre (0‚Äì9) et teste le mod√®le")

    st.markdown("""
    Dessine un chiffre dans la zone ci-dessous.  
    Il sera automatiquement converti en **image MNIST 28√ó28**, normalis√©,
    puis envoy√© au **mod√®le actif**.
    """)

    # -----------------------------------------------------------
    #  Choix du mod√®le actif (runs persist√©s)
    # -----------------------------------------------------------

    all_models = list(st.session_state.all_runs.keys())

    if not all_models:
        st.warning("Aucun mod√®le sauvegard√©. Entra√Æne un mod√®le pour commencer.")
    else:
        # Pr√©selection : le mod√®le actif actuel
        default_index = (
            all_models.index(st.session_state.current_run["run_id"])
            if st.session_state.current_run and st.session_state.current_run["run_id"] in all_models
            else 0
        )

        selected_run_id = st.selectbox(
            "S√©lectionne un mod√®le √† utiliser",
            all_models,
            index=default_index
        )

        # Charger ce mod√®le
        model_data = st.session_state.all_runs[selected_run_id]["model"]
        net = Network(model_data["sizes"])
        net.weights = model_data["weights"]
        net.biases = model_data["biases"]

        # -----------------------------------------------------------
        #  Canvas
        # -----------------------------------------------------------

        st.markdown("### üìù Zone de dessin")

        if "canvas_key" not in st.session_state:
            st.session_state.canvas_key = 0

        if st.button("üßΩ Effacer le dessin"):
            st.session_state.canvas_key += 1

        canvas_result = st_canvas(
            fill_color="rgba(0,0,0,0)",
            stroke_width=20,
            stroke_color="#FFFFFF",
            background_color="#000000",
            height=400,
            width=400,
            drawing_mode="freedraw",
            key=f"canvas_{st.session_state.canvas_key}"
        )

        # -----------------------------------------------------------
        #  Bouton de pr√©diction
        # -----------------------------------------------------------

        if st.button("üîç Pr√©dire le chiffre dessin√©"):
            if canvas_result.image_data is None:
                st.error("Aucun dessin d√©tect√©.")
            else:
                img = canvas_result.image_data

                # Conversion en niveaux de gris
                img_gray = cv2.cvtColor(img.astype("uint8"), cv2.COLOR_BGR2GRAY)

                # Redimension MNIST
                img_resized = cv2.resize(img_gray, (28, 28), interpolation=cv2.INTER_AREA)

                # Normalisation (0‚Äì1)
                img_norm = img_resized / 255.0

                # Format r√©seau 784x1
                x = img_norm.reshape(784, 1)

                # Pr√©diction
                output = net.feedForward(x)
                probs = softmax(output)
                prediction = int(np.argmax(probs))

                st.markdown("## üìå R√©sultat")

                colA, colB = st.columns([1, 2])

                with colA:
                    st.image(
                        img_resized,
                        width=150,
                        caption="Image 28√ó28 envoy√©e au mod√®le"
                    )

                with colB:
                    st.success(f"**Le mod√®le pr√©dit : {prediction}**")

                    import pandas as pd
                    df = pd.DataFrame({
                        "digit": list(range(10)),
                        "proba": probs.ravel(),
                    })
                    st.bar_chart(df.set_index("digit"))


