import os
import pickle
from datetime import datetime

import numpy as np
import streamlit as st

import mnist_loader
from neural_network import Network

import cv2
from streamlit_drawable_canvas import st_canvas

# =========================
#   CSS POUR FORCER LA TAILLE DU CANVAS
# =========================

CANVAS_HEIGHT = 400  # m√™me valeur que dans st_canvas

st.markdown(
    f"""
    <style>
    /* Force la hauteur de l'iframe du composant drawable canvas */
    iframe[title="streamlit_drawable_canvas.st_canvas"] {{
        height: {CANVAS_HEIGHT}px !important;
    }}
    </style>
    """,
    unsafe_allow_html=True,
)

# =========================
#   BOOTSTRAP MODELS SAUV√âS
# =========================

def bootstrap_saved_models():
    if "saved_models" not in st.session_state:
        st.session_state.saved_models = {}

    os.makedirs("saved_models", exist_ok=True)

    for fname in os.listdir("saved_models"):
        if fname.endswith(".pkl"):
            path = os.path.join("saved_models", fname)
            run_id = fname[:-4]  # tu peux parser mieux si tu veux extraire l'accuracy
            if run_id not in st.session_state.saved_models:
                st.session_state.saved_models[run_id] = path

bootstrap_saved_models()




# ==========================
#   CONFIG STREAMLIT
# ==========================

st.set_page_config(
    page_title="MNIST Lab ‚Äì DL Playground",
    layout="wide"
)

st.title("üß† MNIST Deep Learning Lab")
st.caption("Petit labo interactif pour explorer ton r√©seau neuronal MNIST.")

# ==========================
#   CHARGEMENT DES DONN√âES
# ==========================

@st.cache_resource(show_spinner=True)
def load_data():
    training_data, validation_data, test_data = mnist_loader.load_data_wrapper()
    return list(training_data), list(validation_data), list(test_data)

training_data, validation_data, test_data = load_data()

# ==========================
#   STATE GLOBAL
# ==========================

if "log_text" not in st.session_state:
    st.session_state.log_text = ""

if "metrics_history" not in st.session_state:
    # liste de dicts {run_id, epoch, test_accuracy, ...}
    st.session_state.metrics_history = []

if "current_run" not in st.session_state:
    st.session_state.current_run = None

if "misclassified_cache" not in st.session_state:
    st.session_state.misclassified_cache = {}

if "saved_models" not in st.session_state:
    # run_id -> path mod√®le
    st.session_state.saved_models = {}

if "weight_history" not in st.session_state:
    # run_id -> {
    #   "epochs": [1, 2, 3, ...],
    #   "w0_list": [W0_epoch1, W0_epoch2, ...]  (poids de la premi√®re couche)
    # }
    st.session_state.weight_history = {}

# ==========================
#   FONCTIONS UTILITAIRES
# ==========================

def append_log(msg: str):
    # On met √† jour le buffer texte
    st.session_state.log_text += msg + "\n"

    # Si on a un placeholder pour le terminal, on le met √† jour en live
    placeholder = st.session_state.get("log_placeholder", None)
    if placeholder is not None:
        placeholder.text_area(
            "Output",
            value=st.session_state.log_text,
            height=400,
        )

def clear_log():
    st.session_state.log_text = ""

def softmax(a):
    a = a - np.max(a)
    exp = np.exp(a)
    return exp / np.sum(exp)

def forward_with_activations(net: Network, x):
    """
    Retourne (zs, activations) pour toutes les couches.
    """
    activation = x
    activations = [x]
    zs = []
    for b, w in zip(net.biases, net.weights):
        z = np.dot(w, activation) + b
        zs.append(z)
        activation = net.sigmoid(z)
        activations.append(activation)
    return zs, activations

def get_misclassified(net: Network, test_data, max_samples=32):
    """
    Retourne une liste de tuples (x, y_true, y_pred, probs)
    """
    samples = []
    for x, y in test_data:
        a = net.feedForward(x)
        probs = softmax(a)
        y_pred = int(np.argmax(probs))
        y_true = int(y)
        if y_pred != y_true:
            samples.append((x, y_true, y_pred, probs))
            if len(samples) >= max_samples:
                break
    return samples

def compute_weight_stats(net: Network):
    """
    Retourne des stats simples sur les poids.
    """
    all_weights = np.concatenate([w.ravel() for w in net.weights])
    return {
        "mean": float(np.mean(all_weights)),
        "std": float(np.std(all_weights)),
        "min": float(np.min(all_weights)),
        "max": float(np.max(all_weights)),
    }

def save_model(net: Network, run_id: str, accuracy: float = None) -> str:
    """
    Sauvegarde seulement les param√®tres du r√©seau (sizes, biais, poids),
    et pas l'objet Network complet, pour √©viter les probl√®mes de pickle
    avec les reruns Streamlit.
    """
    os.makedirs("saved_models", exist_ok=True)

    filename = (
        f"{run_id}_{accuracy:.4f}.pkl" if accuracy is not None else f"{run_id}.pkl"
    )
    path = os.path.join("saved_models", filename)

    payload = {
        "sizes": net.sizes,
        "biases": net.biases,
        "weights": net.weights,
    }

    with open(path, "wb") as f:
        pickle.dump(payload, f)

    st.session_state.saved_models[run_id] = path
    return path


def load_model(path: str) -> Network:
    """
    Charge un mod√®le sauvegard√©.
    - Nouveau format : dict {sizes, biases, weights}
    - Ancien format (si tu as des vieux .pkl) : instance Network pickl√©e
    """
    with open(path, "rb") as f:
        obj = pickle.load(f)

    # Compatibilit√© avec les anciens fichiers o√π on picklait directement Network
    if isinstance(obj, Network):
        return obj

    # Nouveau format : dict de param√®tres
    if isinstance(obj, dict):
        sizes = obj["sizes"]
        net = Network(sizes)
        net.biases = obj["biases"]
        net.weights = obj["weights"]
        return net

    raise TypeError(f"Format de mod√®le inconnu dans {path}: {type(obj)}")


def compute_confusion_matrix(net: Network, data, num_classes: int = 10):
    """
    Calcule une matrice de confusion (num_classes x num_classes)
    sur un dataset de la forme [(x, y_true), ...].

    Lignes  = classes r√©elles
    Colonnes = classes pr√©dites
    """
    cm = np.zeros((num_classes, num_classes), dtype=int)

    for x, y_true in data:
        a = net.feedForward(x)
        y_pred = int(np.argmax(a))
        y_true = int(y_true)
        if 0 <= y_true < num_classes and 0 <= y_pred < num_classes:
            cm[y_true, y_pred] += 1

    return cm

# ==========================
#   SIDEBAR ‚Äì CONTROLS
# ==========================

st.sidebar.header("Hyperparam√®tres")

epochs = st.sidebar.slider("Epochs", 1, 50, 10)
learning_rate = st.sidebar.slider("Learning rate (Œ∑)", 0.01, 5.0, 3.0, step=0.01)
mini_batch_size = st.sidebar.slider("Mini-batch size", 1, 100, 10)

st.sidebar.markdown("---")
st.sidebar.subheader("Architecture")

hidden_size = st.sidebar.slider("Taille couche cach√©e", 10, 300, 100)
# Tu peux ajouter plusieurs couches plus tard (liste de sliders, etc.)

st.sidebar.markdown("---")
st.sidebar.subheader("Options d'entra√Ænement")

use_validation = st.sidebar.checkbox("Utiliser validation comme test", value=False)
limit_train = st.sidebar.number_input(
    "Limiter le nb d'exemples d'entra√Ænement (0 = tout)",
    min_value=0,
    max_value=len(training_data),
    value=0,
    step=1000,
)

# ==========================
#   LAYOUT PRINCIPAL
# ==========================

tab_readme, tab_train, tab_draw, tab_activations, tab_weights, tab_metrics, tab_errors = st.tabs(
    ["üìñ Readme", "üì° Entra√Ænement", "üñäÔ∏è Dessiner & Tester","‚ú® Activations", "üßÆ Poids", "üìà M√©triques", "üïµÔ∏è Erreurs"]
)

# ========== ONGLET README ==========
with tab_readme:
    st.subheader("Bienvenue dans le MNIST Deep Learning Lab üëã")

    st.markdown("""
## üìö Qu‚Äôest-ce que MNIST ?

MNIST, c‚Äôest un petit classique du machine learning.  
Il s‚Äôagit d‚Äôun jeu de donn√©es contenant **70 000 images de chiffres manuscrits** (de 0 √† 9), chacune en **28√ó28 pixels**.  
Les images proviennent de milliers de personnes diff√©rentes, ce qui en fait un terrain parfait pour apprendre comment un mod√®le reconna√Æt des motifs visuels.

En bref :  
> MNIST, c‚Äôest le *‚ÄúHello World‚Äù* du Deep Learning ‚Äî simple, propre, et id√©al pour comprendre les bases.

---

## üéØ 1. √Ä quoi sert cette application ?

Ce site te permet de **configurer**, **entra√Æner** et **tester** ton propre r√©seau de neurones, le tout sans √©crire une seule ligne de code.

Tu peux :

### üîß Configurer ton r√©seau
- Choisir la taille de la couche cach√©e  
- Ajuster les hyperparam√®tres (epochs, learning rate, mini-batch‚Ä¶)  
- Activer certaines options d‚Äôentra√Ænement  

### üöÄ Lancer l‚Äôentra√Ænement
- Suivre la progression dans un terminal en direct  
- Visualiser l‚Äô√©volution de l‚Äôaccuracy  
- Voir les erreurs, les activations internes et m√™me les poids appris par le mod√®le  

### ‚úèÔ∏è Tester le mod√®le
- Sur des images MNIST r√©elles  
- Ou en dessinant toi-m√™me un chiffre dans un canvas interactif

L‚Äôobjectif est p√©dagogique : comprendre *comment* un r√©seau apprend, et *pourquoi* il se trompe parfois.

---

## üß© 2. Comment fonctionne un r√©seau de neurones ? (Version simple)

Un r√©seau de neurones, c‚Äôest un ensemble de ‚Äúcouches‚Äù qui transforment progressivement une entr√©e (ici, une image 28√ó28) pour pr√©dire un chiffre.

### Structure typique :
- **Input** : 784 pixels (28√ó28)
- **Hidden layer** : une couche de neurones interm√©diaires
- **Output** : 10 neurones (un par chiffre 0‚Äì9)

√Ä chaque √©tape :

1. Les neurones re√ßoivent des nombres (les intensit√©s des pixels)
2. Ils les multiplient par des **poids**
3. Ils appliquent une fonction (sigmo√Øde)
4. Ils transmettent le r√©sultat √† la couche suivante

Pendant l‚Äôentra√Ænement, le mod√®le :

- fait une pr√©diction  
- mesure l‚Äôerreur  
- ajuste ses poids pour faire mieux au prochain passage  

En r√©p√©tant √ßa des milliers de fois ‚Üí il apprend.

---

## ‚öôÔ∏è 3. Les hyperparam√®tres : ce qu‚Äôils font, et comment les r√©gler

Les hyperparam√®tres sont les r√©glages qui influencent *comment* le mod√®le apprend.

### üî∏ **Epochs**
Le nombre de fois o√π le mod√®le passe sur **tout** le dataset.

- Peu : mod√®le pas assez entra√Æn√©  
- Trop : risque de m√©moriser inutilement  

üí° Pour MNIST : **10 √† 30 epochs suffisent largement**

---

### üî∏ **Learning rate (Œ∑)**
La ‚Äúvitesse d‚Äôapprentissage‚Äù.

- Trop faible ‚Üí apprentissage lent  
- Trop fort ‚Üí instable, le mod√®le oscille ou diverge  

üí° Pour ce r√©seau : **entre 0.5 et 3.0 fonctionne tr√®s bien**

---

### üî∏ **Mini-batch size**
Nombre d‚Äôexemples utilis√©s avant chaque mise √† jour des poids.

- Petit batch ‚Üí apprentissage plus ‚Äúvivant‚Äù, mais plus bruit√©  
- Gros batch ‚Üí plus stable, mais peut donner des r√©sultats moins bons  

üí° Valeurs conseill√©es : **10 √† 50**

---

## üß± 4. La couche cach√©e (Hidden Layer)

La couche cach√©e est le c≈ìur du mod√®le : c‚Äôest l√† qu‚Äôil apprend les **motifs** caract√©ristiques des chiffres :

- courbes  
- angles  
- tiges verticales  
- coins  
- boucles  
- etc.

Plus la hidden layer est grande :

- plus le mod√®le peut apprendre de choses  
- mais plus il devient lent, et plus il risque de surapprendre

üí° Pour MNIST : **entre 50 et 150 neurones**, c‚Äôest un bon compromis.

---

## üß™ 5. Les options d‚Äôentra√Ænement

### üî∏ Utiliser la validation comme test
Permet d‚Äô√©valuer le mod√®le *sans toucher au vrai jeu de test*.  
C‚Äôest pratique pour ajuster les hyperparam√®tres sans ‚Äútricher‚Äù sur les performances r√©elles.

### üî∏ Limiter le nombre d‚Äôexemples d‚Äôentra√Ænement
Tu peux choisir de n‚Äôentra√Æner le mod√®le que sur une partie du dataset.

Utile pour :
- des tests rapides  
- √©conomiser les ressources  
- observer comment la quantit√© de donn√©es influence l‚Äôapprentissage  

üí° 0 = utiliser tout MNIST (valeur normale)

---

## üöÄ 6. Lancer l‚Äôentra√Ænement

1. Choisis :
   - la taille de la hidden layer  
   - les hyperparam√®tres  
   - les options d‚Äôentra√Ænement  

2. Clique sur **Start training**

3. Observe :
   - le terminal qui se met √† jour  
   - les courbes d‚Äô√©volution  
   - les erreurs et activations internes  
   - les poids du r√©seau  

√Ä la fin, un mod√®le est automatiquement sauvegard√©.

---

## ‚úèÔ∏è 7. Tester ton mod√®le (canvas de dessin)

Dans l‚Äôonglet **üñäÔ∏è Dessiner & Tester** :

- s√©lectionne un mod√®le sauvegard√©  
- dessine un chiffre √† la souris  

Le dessin est automatiquement :

- converti en image 28√ó28  
- normalis√©  
- pass√© au mod√®le

Le r√©seau te renvoie :
- sa pr√©diction  
- les probabilit√©s associ√©es (softmax)

---

N‚Äôh√©site pas √† explorer, tester plusieurs hyperparam√®tres et comparer les r√©sultats.  
Amuse-toi bien avec le Deep Learning üôÇ
""")




# ========== ONGLET TRAINING ==========

with tab_train:
    col_left, col_right = st.columns([2, 1])

    with col_left:
        st.subheader("Lancer un entra√Ænement")

        start_training = st.button("üöÄ Start training")

        st.markdown("### Terminal")

        # On cr√©e (ou r√©cup√®re) le placeholder pour le terminal
        if "log_placeholder" not in st.session_state or st.session_state.log_placeholder is None:
            st.session_state.log_placeholder = st.empty()

        log_box = st.session_state.log_placeholder

        # Affichage initial du contenu
        log_box.text_area(
            "Output",
            value=st.session_state.log_text,
            height=400,
        )

    with col_right:
        st.subheader("Dernier run")

        if st.session_state.current_run is not None:
            run = st.session_state.current_run
            st.write(f"**Run ID :** `{run['run_id']}`")
            st.write(f"**Date :** {run['timestamp']}")
            st.write(f"**Architecture :** {run['sizes']}")
            if "final_accuracy" in run:
                st.metric("Accuracy test", f"{run['final_accuracy']*100:.2f} %")
        else:
            st.info("Aucun run pour le moment.")

# ========== CALLBACK D'ENTRA√éNEMENT ==========

def make_epoch_callback(run_id):
    def epoch_callback(epoch, metrics, network: Network):
        # log text
        # if "test_accuracy" in metrics:
        #     append_log(
        #         f"[{run_id}] Epoch {epoch}/{metrics['epochs']} "
        #         f"- test_acc={metrics['test_accuracy']:.4f}"
        #     )
        # else:
        #     append_log(f"[{run_id}] Epoch {epoch}/{metrics['epochs']} complete")
        
        # ---------- Metrics history pour les graphes ----------
        entry = {
            "run_id": run_id,
            "epoch": epoch,
        }
        entry.update(metrics)
        st.session_state.metrics_history.append(entry)

        # ---------- Historique des poids de la premi√®re couche ----------
        if "weight_history" not in st.session_state:
            st.session_state.weight_history = {}

        if run_id not in st.session_state.weight_history:
            st.session_state.weight_history[run_id] = {
                "epochs": [],
                "w0_list": [],
            }

        hist = st.session_state.weight_history[run_id]

        # On logge l'epoch
        hist["epochs"].append(epoch)

        # Snapshot des poids de la premi√®re couche (input -> hidden)
        if len(network.weights) > 0:
            # copie pour ne pas √™tre √©cras√© par les updates suivants
            hist["w0_list"].append(network.weights[0].copy())

    return epoch_callback
# ========== FONCTION POUR TRAINING AVEC PARAM√àTRES CUSTOM (AutoML) ==========

def run_single_training_with_params(eta, batch, cfg_name="automl"):
    """
    Identique √† run_single_training(), mais accepte des hyperparam√®tres custom.
    Utilis√© par AutoML pour √©viter l'usage de global variables.
    """
    clear_log()

    # Pr√©pare les donn√©es
    if limit_train and limit_train > 0:
        train_subset = training_data[:limit_train]
    else:
        train_subset = training_data

    test_set = validation_data if use_validation else test_data

    # Cr√©e le r√©seau
    sizes = [784, hidden_size, 10]
    net = Network(sizes)

    run_id = f"{cfg_name}-{datetime.now().strftime('%Y%m%d-%H%M%S')}"

    st.session_state.current_run = {
        "run_id": run_id,
        "sizes": sizes,
        "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "config_name": cfg_name,
    }

    append_log(f"=== NEW RUN {run_id} ===")
    append_log(f"Architecture: {sizes}")
    append_log(f"Epochs={epochs}, eta={eta}, mini_batch={batch}")
    append_log(f"Train samples={len(train_subset)}, Test samples={len(test_set)}")
    append_log(f"======================================")

    # Lancer SGD avec callback
    net.SGD(
        training_data=train_subset,
        epochs=epochs,
        mini_batch_size=batch,
        eta=eta,
        test_data=test_set,
        log_fn=append_log,
        epoch_callback=make_epoch_callback(run_id),
    )

    # Accuracy finale
    correct = net.evaluate(test_set)
    final_acc = correct / len(test_set)
    st.session_state.current_run["final_accuracy"] = final_acc

    # Sauver mod√®le
    model_path = save_model(net, run_id, accuracy=final_acc)
    st.session_state.current_run["model_path"] = model_path

    # Pr√©-calcul erreurs
    st.session_state.misclassified_cache[run_id] = get_misclassified(net, test_set)

    return run_id, net

def run_single_training(cfg_name="manual"):
    """
    Entra√Ænement normal en utilisant les valeurs des sliders
    (learning_rate, mini_batch_size).
    """
    return run_single_training_with_params(
        eta=learning_rate,
        batch=mini_batch_size,
        cfg_name=cfg_name,
    )

if start_training:
    run_single_training(cfg_name="manual")


# ========== ONGLET M√âTRIQUES ==========
with tab_metrics:
    st.subheader("üìà M√©triques d'entra√Ænement et de performance")

    if not st.session_state.metrics_history:
        st.info("Aucune m√©trique pour l'instant. Lance un entra√Ænement pour voir les courbes.")
    else:
        import pandas as pd

        df = pd.DataFrame(st.session_state.metrics_history)
        run_ids = df["run_id"].unique().tolist()
        selected_run = st.selectbox("S√©lectionne un run √† analyser", run_ids)

        df_run = df[df["run_id"] == selected_run].sort_values("epoch")

        # ---------- COURBES DE BASE ----------
        st.markdown("### Courbes de base")

        col1, col2 = st.columns(2)

        with col1:
            if "test_accuracy" in df_run:
                st.line_chart(
                    df_run.set_index("epoch")["test_accuracy"],
                    height=300,
                )
                st.caption("Accuracy sur le set de test (ou validation) en fonction des epochs.")

        with col2:
            if "test_correct" in df_run:
                st.bar_chart(
                    df_run.set_index("epoch")["test_correct"],
                    height=300,
                )
                st.caption("Nombre de pr√©dictions correctes par epoch.")

    # ---------- SUITE : GUIDES / VISUS AVANC√âES ----------
    st.markdown("---")
    st.markdown("### üìö Guide de lecture des visualisations")

 # 1Ô∏è‚É£ Loss par epoch (avec courbe dans l'expander)
    with st.expander("üß† Loss par epoch"):
        st.markdown(
            """
La **loss** mesure √† quel point le mod√®le se trompe en moyenne.

- Apr√®s chaque epoch, on calcule une valeur de loss sur le jeu d'entra√Ænement.
- Normalement, la loss doit **descendre** progressivement si le mod√®le apprend correctement.
"""
        )

        # On v√©rifie que metrics_history n'est pas vide
        if not st.session_state.metrics_history:
            st.info("Aucune loss disponible : lance un entra√Ænement pour voir la courbe.")
        else:
            import pandas as pd

            df = pd.DataFrame(st.session_state.metrics_history)
            run_ids = df["run_id"].unique().tolist()
            
            selected_run_loss = st.selectbox(
                "S√©lectionne un run pour afficher la loss",
                run_ids,
                key="select_run_loss"
            )

            df_run_loss = df[df["run_id"] == selected_run_loss].sort_values("epoch")

            # V√©rification de la dispo de la loss
            if "train_loss" not in df_run_loss:
                st.warning("Ce run ne contient pas de valeurs de loss.")
            else:
                st.line_chart(
                    df_run_loss.set_index("epoch")["train_loss"],
                    height=300
                )

                last_loss = df_run_loss["train_loss"].iloc[-1]
                st.metric(
                    "Derni√®re loss enregistr√©e",
                    f"{last_loss:.4f}"
                )

        st.caption("La loss est calcul√©e avec un MSE simple : 0.5 * || pr√©diction - v√©rit√© ||¬≤")

    # 2Ô∏è‚É£ TSNE / PCA des embeddings de la hidden layer (interactif)
    with st.expander("üß© TSNE / PCA de la couche cach√©e (interactif)"):
        st.markdown(
            """
On projette ici les activations de la **couche cach√©e** dans un plan 2D
pour voir comment le r√©seau s√©pare les chiffres dans son espace interne.

Chaque point = une image MNIST, color√©e selon son vrai chiffre.
"""
        )

        # On ne peut rien faire tant qu'aucun mod√®le n'a √©t√© entra√Æn√©/sauvegard√©
        if st.session_state.current_run is None or "model_path" not in st.session_state.current_run:
            st.info("Lance au moins un entra√Ænement pour pouvoir calculer la projection TSNE/PCA.")
        else:
            run = st.session_state.current_run
            net = load_model(run["model_path"])

            import pandas as pd
            import altair as alt

            max_samples = len(test_data)
            if max_samples == 0:
                st.warning("Le set de test est vide, impossible de calculer la projection.")
            else:
                st.markdown("#### Param√®tres de la projection")

                n_samples = st.slider(
                    "Nombre d'images √† projeter",
                    min_value=100,
                    max_value=min(2000, max_samples),
                    value=min(500, max_samples),
                    step=100,
                    help="Plus il y a de points, plus la projection est riche, mais plus le calcul est long."
                )

                method = st.radio(
                    "M√©thode de r√©duction de dimension",
                    ["PCA (rapide)", "t-SNE (plus lent, plus joli)"],
                    help="PCA donne une id√©e rapide, t-SNE donne souvent des clusters plus nets."
                )

                if st.button("Calculer la projection 2D"):
                    from sklearn.decomposition import PCA
                    from sklearn.manifold import TSNE

                    # R√©cup√©ration des activations de la couche cach√©e
                    X = []
                    y_labels = []
                    for i, (x, y_true) in enumerate(test_data[:n_samples]):
                        _, activations = forward_with_activations(net, x)
                        hidden = activations[1]  # premi√®re couche cach√©e
                        X.append(hidden.ravel())
                        y_labels.append(int(y_true))

                    X = np.array(X)

                    # Choix du r√©ducteur de dimension
                    if method.startswith("PCA"):
                        reducer = PCA(n_components=2)
                    else:
                        # t-SNE : plus lent, mais meilleure s√©paration visuelle
                        reducer = TSNE(
                            n_components=2,
                            init="random",
                            learning_rate="auto",
                            perplexity=min(30, n_samples - 1),
                        )

                    with st.spinner("Calcul de la projection en 2D..."):
                        emb = reducer.fit_transform(X)

                    df_emb = pd.DataFrame({
                        "x": emb[:, 0],
                        "y": emb[:, 1],
                        "label": y_labels,
                    })

                    st.markdown("#### Projection des embeddings de la couche cach√©e")

                    chart = alt.Chart(df_emb).mark_circle(size=50, opacity=0.8).encode(
                        x="x",
                        y="y",
                        color="label:N",
                        tooltip=["label:N"],
                    ).properties(
                        height=400
                    )

                    st.altair_chart(chart, use_container_width=True)

                    st.caption(
                        "Chaque point est une image MNIST projet√©e dans l'espace latent. "
                        "Les couleurs correspondent aux chiffres r√©els (0‚Äì9). "
                        "On cherche √† voir si les classes se regroupent bien."
                    )

    # 4Ô∏è‚É£ Animation de l‚Äô√©volution des poids d‚Äôun neurone
    with st.expander("üéûÔ∏è Animation de l‚Äô√©volution des poids d‚Äôun neurone"):
        st.markdown(
            """
Chaque neurone de la couche cach√©e poss√®de **784 poids** (un par pixel).  
Si on reshape ce vecteur en 28√ó28, on obtient une image qui repr√©sente **le motif auquel ce neurone est sensible**.

Id√©e de visualisation :
- pour un neurone donn√©,
- on enregistre ses poids √† diff√©rents epochs,
- puis on affiche une **s√©rie d‚Äôimages** (ou un slider temporel) qui montre comment ce motif √©volue.

Ce que l‚Äôon voit :
- au d√©but, les poids ressemblent √† du bruit ;
- progressivement, des formes apparaissent (traits verticaux, courbes, zones sombres/claires) ;
- le neurone se ‚Äúsp√©cialise‚Äù dans un type de motif.

> C‚Äôest une excellente mani√®re d‚Äôillustrer qu‚Äôun r√©seau n‚Äôest pas une bo√Æte noire magique, mais qu‚Äôil apprend effectivement des patrons visuels.
"""
        )

        # --- Partie interactive : slider sur neurone & epoch ---
        if "weight_history" not in st.session_state or not st.session_state.weight_history:
            st.info("Aucun historique de poids disponible. Lance un entra√Ænement pour commencer √† enregistrer les poids.")
        else:
            import pandas as pd  # au cas o√π tu en as besoin plus bas

            run_ids_hist = list(st.session_state.weight_history.keys())

            selected_run_anim = st.selectbox(
                "S√©lectionne un run pour visualiser l'√©volution d'un neurone",
                run_ids_hist,
                key="select_run_weight_anim",
            )

            hist = st.session_state.weight_history.get(selected_run_anim, None)

            if hist is None or len(hist.get("w0_list", [])) == 0:
                st.warning("Pas encore d'historique de poids pour ce run.")
            else:
                epochs_hist = hist["epochs"]
                w0_list = hist["w0_list"]  # liste de matrices (hidden_size, 784)

                # On suppose que la taille de la couche cach√©e ne change pas au cours du run
                hidden_size_hist = w0_list[0].shape[0]

                col_sel1, col_sel2 = st.columns(2)
                with col_sel1:
                    neuron_idx = st.slider(
                        "Indice du neurone cach√©",
                        min_value=0,
                        max_value=hidden_size_hist - 1,
                        value=0,
                        key="anim_neuron_idx",
                    )
                with col_sel2:
                    if len(epochs_hist) <= 1:
                        # Un seul epoch disponible ‚Üí pas de slider
                        epoch_pos = 0
                        st.info("Une seule epoch enregistr√©e pour ce run.")
                    else:
                        epoch_pos = st.slider(
                            "Epoch",
                            min_value=0,
                            max_value=len(epochs_hist) - 1,
                            value=len(epochs_hist) - 1,
                            key="anim_epoch_idx",
                        )

                epoch_val = epochs_hist[epoch_pos]
                # Poids du neurone s√©lectionn√© √† cette epoch
                w_vec = w0_list[epoch_pos][neuron_idx, :]  # shape (784,)
                img = w_vec.reshape(28, 28)

                # Normalisation locale pour l'affichage
                w_min, w_max = img.min(), img.max()
                if w_max > w_min:
                    img_norm = (img - w_min) / (w_max - w_min)
                else:
                    img_norm = np.zeros_like(img)

                st.image(
                    img_norm,
                    width=160,
                    clamp=True,
                    caption=f"Run {selected_run_anim} ‚Äì neurone {neuron_idx}, epoch {epoch_val}",
                )

                # Option : courbe de la norme des poids de ce neurone au cours du temps
                show_norms = st.checkbox(
                    "Afficher l'√©volution de la norme des poids de ce neurone",
                    value=False,
                    key="show_neuron_norm_curve",
                )

                if show_norms:
                    norms = [float(np.linalg.norm(w0[neuron_idx, :])) for w0 in w0_list]
                    df_norm = pd.DataFrame(
                        {"epoch": epochs_hist, "weight_norm": norms}
                    ).set_index("epoch")
                    st.line_chart(df_norm)
                    st.caption("La norme des poids donne une id√©e de la 'force' du filtre appris par ce neurone.")

    # 5Ô∏è‚É£ Matrice de confusion
    with st.expander("üßÆ Matrice de confusion"):
        st.markdown(
            """
La **matrice de confusion** r√©sume comment le mod√®le se trompe entre les classes.

- en lignes : la *vraie* classe (0, 1, 2, ‚Ä¶, 9)
- en colonnes : la classe *pr√©dite* par le mod√®le
- chaque case contient le nombre d‚Äôexemples correspondant

On s‚Äôattend √† ce que la **diagonale** soit dominante (bonnes pr√©dictions).
"""
        )

        # V√©rifier qu'on a bien un mod√®le entra√Æn√©
        if st.session_state.current_run is None or "model_path" not in st.session_state.current_run:
            st.info("Lance un entra√Ænement pour pouvoir calculer la matrice de confusion.")
        else:
            run = st.session_state.current_run
            net = load_model(run["model_path"])

            import pandas as pd
            import altair as alt

            # Choix du dataset
            dataset_choice = st.radio(
                "Dataset utilis√© pour la matrice de confusion",
                ["Test set", "Validation set"],
                horizontal=True,
                key="confusion_dataset_choice",
            )

            if dataset_choice == "Test set":
                data = test_data
            else:
                data = validation_data

            if len(data) == 0:
                st.warning("Le dataset s√©lectionn√© est vide, impossible de calculer la matrice de confusion.")
            else:
                # Option : limiter le nombre d'exemples pour aller plus vite
                max_samples = len(data)
                n_samples = st.slider(
                    "Nombre d'images utilis√©es pour la matrice",
                    min_value=100,
                    max_value=max_samples,
                    value=min(1000, max_samples),
                    step=100,
                    key="confusion_n_samples",
                    help="Plus il y a d'images, plus la matrice est repr√©sentative (mais plus c'est long).",
                )

                if st.button("Calculer la matrice de confusion", key="confusion_button"):
                    subset = data[:n_samples]

                    with st.spinner("Calcul en cours..."):
                        cm = compute_confusion_matrix(net, subset, num_classes=10)

                    total = cm.sum()
                    correct = np.trace(cm)
                    acc = correct / total if total > 0 else 0.0

                    st.markdown(f"**Accuracy sur cet √©chantillon : {acc*100:.2f} %**")

                    # Pr√©parer les donn√©es pour un heatmap Altair
                    df_cm = pd.DataFrame(cm, index=range(10), columns=range(10))
                    df_plot = (
                        df_cm
                        .reset_index()
                        .melt(id_vars="index", var_name="pred", value_name="count")
                        .rename(columns={"index": "true"})
                    )

                    st.markdown("### Heatmap de la matrice de confusion")

                    chart = (
                        alt.Chart(df_plot)
                        .mark_rect()
                        .encode(
                            x=alt.X("pred:O", title="Classe pr√©dite"),
                            y=alt.Y("true:O", title="Classe r√©elle"),
                            color=alt.Color("count:Q", scale=alt.Scale(scheme="blues")),
                            tooltip=["true", "pred", "count"],
                        )
                        .properties(height=400)
                    )

                    st.altair_chart(chart, use_container_width=True)

                    st.caption(
                        "Les valeurs sur la diagonale correspondent aux pr√©dictions correctes. "
                        "Les cases hors diagonale montrent quelles classes sont le plus souvent confondues."
                    )


# ========== ONGLET ERREURS ==========

with tab_errors:
    st.subheader("Images mal class√©es")

    if st.session_state.current_run is None:
        st.info("Lance un run pour voir les erreurs.")
    else:
        run_id = st.session_state.current_run["run_id"]
        miscls = st.session_state.misclassified_cache.get(run_id)

        if not miscls:
            st.info("Pas d'erreurs trouv√©es (ou pas encore calcul√©es).")
        else:
            st.write(f"{len(miscls)} exemples mal class√©s (montr√©s au max).")

            cols = st.columns(8)
            for i, (x, y_true, y_pred, probs) in enumerate(miscls):
                col = cols[i % len(cols)]
                img = np.reshape(x, (28, 28))
                with col:
                    st.image(img, width=60, caption=f"True:{y_true} / Pred:{y_pred}")

# ========== ONGLET ACTIVATIONS ==========

with tab_activations:
    st.subheader("Explorateur d'activations")

    if st.session_state.current_run is None or "model_path" not in st.session_state.current_run:
        st.info("Lance un entra√Ænement pour analyser les activations.")
    else:
        run = st.session_state.current_run
        net = load_model(run["model_path"])

        index = st.slider(
            "Index d'image dans le set de test",
            min_value=0,
            max_value=len(test_data) - 1,
            value=0,
        )

        x, y_true = test_data[index]
        img = np.reshape(x, (28, 28))

        col_img, col_info = st.columns([1, 2])

        with col_img:
            st.image(img, width=140, caption=f"Label vrai : {int(y_true)}")

        with col_info:
            zs, activations = forward_with_activations(net, x)
            output = activations[-1]
            probs = softmax(output)

            st.markdown("**Distribution des sorties (softmax)**")
            import pandas as pd
            df_probs = pd.DataFrame({
                "digit": list(range(10)),
                "proba": probs.ravel(),
            })
            st.bar_chart(df_probs.set_index("digit"))

            st.markdown("**Normes d'activation par couche**")
            norms = [float(np.linalg.norm(a)) for a in activations]
            df_norms = pd.DataFrame({
                "layer": list(range(len(norms))),
                "activation_norm": norms,
            })
            st.line_chart(df_norms.set_index("layer"))

# ========== ONGLET POIDS ==========

with tab_weights:
    st.subheader("Analyse des poids")

    if st.session_state.current_run is None or "model_path" not in st.session_state.current_run:
        st.info("Lance un entra√Ænement pour voir les poids.")
    else:
        run = st.session_state.current_run
        net = load_model(run["model_path"])

        stats = compute_weight_stats(net)
        col1, col2, col3, col4 = st.columns(4)
        col1.metric("Mean", f"{stats['mean']:.4e}")
        col2.metric("Std", f"{stats['std']:.4e}")
        col3.metric("Min", f"{stats['min']:.4e}")
        col4.metric("Max", f"{stats['max']:.4e}")

        st.markdown("---")
        st.markdown("### Repr√©sentation des poids entre la couche d‚Äôentr√©e et la couche cach√©e")

        
        w0 = net.weights[0]  # shape (hidden_size, 784)
        cols = st.columns(10)
        for i in range(min(10, w0.shape[0])):
            col = cols[i % len(cols)]
            with col:
                img_w = w0[i, :].reshape(28, 28)

                # Normalisation locale pour ce neurone : [0, 1]
                w_min = img_w.min()
                w_max = img_w.max()
                if w_max > w_min:
                    img_w_norm = (img_w - w_min) / (w_max - w_min)
                else:
                    # cas d√©g√©n√©r√© : tous les poids identiques
                    img_w_norm = np.zeros_like(img_w)

                st.image(img_w_norm, width=60, caption=f"Neuron {i}")


        st.markdown("---")
        st.markdown("### Repr√©sentation des poids entre la couche cach√©e et la couche de sortie")

        # Les poids de la derni√®re couche : shape (10, hidden_size)
        w_out = net.weights[-1]  

        # Chaque neurone de sortie utilise les 'features' produites par les hidden neurons
        # On va reconstruire une image 28x28 en faisant une combinaison pond√©r√©e 
        # des poids input->hidden, pond√©r√©e par les poids hidden->output.

        w_hidden = net.weights[0]   # shape (hidden_size, 784)

        cols = st.columns(10)
        for digit in range(10):
            col = cols[digit % len(cols)]
            with col:
                # Combinaison lin√©aire des filtres cach√©s
                # w_out[digit]: shape (hidden_size,)
                combined = np.dot(w_out[digit], w_hidden)  # shape (784,)

                # reshape en image
                img = combined.reshape(28, 28)

                # Normalisation locale pour l'affichage
                mn, mx = img.min(), img.max()
                if mx > mn:
                    img_norm = (img - mn) / (mx - mn)
                else:
                    img_norm = np.zeros_like(img)

                st.image(img_norm, width=60, caption=f"Classe {digit}")

        
        st.markdown("---")
        st.markdown("### Histogramme global des poids")

        all_weights = np.concatenate([w.ravel() for w in net.weights])
        import matplotlib.pyplot as plt

        fig, ax = plt.subplots()
        ax.hist(all_weights, bins=50)
        ax.set_title("Distribution des poids")
        ax.set_xlabel("valeur")
        ax.set_ylabel("fr√©quence")
        st.pyplot(fig)

# ========== ONGLET : Dessiner & Tester ==========

with tab_draw:
    st.subheader("üñäÔ∏è Dessine un chiffre et teste un mod√®le MNIST")

    st.markdown("""
    Dessine un chiffre (0‚Äì9) dans la zone ci-dessous.  
    Il sera automatiquement **converti en MNIST 28√ó28** puis envoy√© au mod√®le.
    """)

    # Pour pouvoir reset le canvas en changeant la key
    if "canvas_key" not in st.session_state:
        st.session_state.canvas_key = 0

    # 1. Choix du mod√®le sauvegard√©
    saved_files = list(st.session_state.saved_models.values())

    if not saved_files:
        st.warning("Aucun mod√®le sauvegard√©. Entra√Æne un r√©seau pour en g√©n√©rer un.")
    else:
        model_file = st.selectbox("Choisis un mod√®le :", saved_files)
        net = load_model(model_file)

        st.markdown("### Zone de dessin")

        # Bouton pour effacer le canvas
        if st.button("üßΩ Effacer le dessin"):
            st.session_state.canvas_key += 1  # change la key pour reset le canvas

        # Canvas Streamlit (key d√©pendante de canvas_key)
        canvas_result = st_canvas(
            fill_color="rgba(0,0,0,0)",
            stroke_width=20,
            stroke_color="#FFFFFF",
            background_color="#000000",
            height=400,
            width=400,
            drawing_mode="freedraw",
            key=f"canvas_{st.session_state.canvas_key}",
        )

        # Bouton de pr√©diction
        if st.button("üîç Pr√©dire le chiffre dessin√©"):
            if canvas_result.image_data is None:
                st.error("Dessin vide (ou pas encore de trait d√©tect√©).")
            else:
                img = canvas_result.image_data

                # Convertir en niveaux de gris
                img_gray = cv2.cvtColor(img.astype("uint8"), cv2.COLOR_BGR2GRAY)

                # Inverser les couleurs (MNIST = fond noir, √©criture claire)
                #img_gray = cv2.bitwise_not(img_gray)

                # Redimensionner en 28√ó28
                img_resized = cv2.resize(img_gray, (28, 28), interpolation=cv2.INTER_AREA)

                # Normaliser 0‚Äì1
                img_norm = img_resized / 255.0

                # Aplatir en vecteur (784, 1)
                x = img_norm.reshape(784, 1)

                # Pr√©diction
                output = net.feedForward(x)
                probs = softmax(output)
                prediction = int(np.argmax(probs))

                st.markdown("### üìå R√©sultat")
                col_a, col_b = st.columns([1, 2])
                with col_a:
                    st.image(img_resized, width=150, caption="Image 28√ó28 envoy√©e au mod√®le")
                with col_b:
                    st.success(f"**Le mod√®le pr√©dit : {prediction}**")
                    st.bar_chart(probs.ravel())